{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T05:46:35.798745Z",
     "start_time": "2025-05-09T05:46:35.189392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä»£ç å— 1.1\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "\n",
    "# è®¾ç½®åŸå§‹æ•°æ®è·¯å¾„\n",
    "data_dir = \"data/raw/CICDDoS2019\"\n",
    "csv_files = glob(os.path.join(data_dir, \"**/*.csv\"), recursive=True)\n",
    "\n",
    "column_counter = Counter()\n",
    "label_summary = {}\n",
    "\n",
    "for path in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(path, nrows=5000)  # è¯»å–å‰5kè¡Œé˜²æ­¢å†…å­˜çˆ†ç‚¸\n",
    "        filename = os.path.basename(path)\n",
    "        df.columns = [col.strip() for col in df.columns]  # å»é™¤åˆ—åç©ºæ ¼\n",
    "        print(f\"âœ… æ–‡ä»¶: {filename}\")\n",
    "        print(f\"   â–¶ï¸ è¡Œæ•°: {df.shape[0]}, åˆ—æ•°: {df.shape[1]}\")\n",
    "        print(f\"   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: {df.isnull().sum().sum()}\")\n",
    "\n",
    "        # ç´¯åŠ å®Œæ•´åˆ—åé¢‘æ¬¡\n",
    "        column_counter.update(df.columns)\n",
    "\n",
    "        # æ ‡ç­¾åˆ—ç»Ÿè®¡\n",
    "        label_col = [col for col in df.columns if 'label' in col.lower() or 'attack' in col.lower()]\n",
    "        if label_col:\n",
    "            label_counts = df[label_col[0]].value_counts()\n",
    "            label_summary[filename] = label_counts.to_dict()\n",
    "            print(f\"   ğŸ·ï¸ æ ‡ç­¾åˆ—: {label_col[0]}, åˆ†å¸ƒ: {label_counts.to_dict()}\")\n",
    "        else:\n",
    "            print(\"   âš ï¸ æœªæ‰¾åˆ°æ ‡ç­¾åˆ—\")\n",
    "        print(\"-\" * 60)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è¯»å–å¤±è´¥: {path}, åŸå› : {e}\")\n",
    "\n",
    "# è¾“å‡ºæ‰€æœ‰åˆ—ååŠé¢‘æ¬¡\n",
    "print(\"\\nğŸ“Š æ‰€æœ‰æ ‡å‡†åŒ–åˆ—ååŠå‡ºç°é¢‘æ¬¡ï¼ˆå…± {} ä¸ªï¼‰ï¼š\".format(len(column_counter)))\n",
    "for col, count in column_counter.most_common():\n",
    "    print(f\"{col}: {count}\")\n"
   ],
   "id": "ed48ea67c8630855",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ–‡ä»¶: DrDoS_DNS.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 1\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'DrDoS_DNS': 4413, 'BENIGN': 587}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: DrDoS_LDAP.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'DrDoS_LDAP': 4999, 'BENIGN': 1}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: DrDoS_MSSQL.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'DrDoS_MSSQL': 5000}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: DrDoS_NetBIOS.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'DrDoS_NetBIOS': 4991, 'BENIGN': 9}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: DrDoS_NTP.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 3\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'BENIGN': 4222, 'DrDoS_NTP': 778}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: DrDoS_SNMP.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'DrDoS_SNMP': 4997, 'BENIGN': 3}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: DrDoS_SSDP.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'DrDoS_SSDP': 4973, 'BENIGN': 27}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: DrDoS_UDP.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'DrDoS_UDP': 5000}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: Syn.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 423\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'Syn': 4998, 'BENIGN': 2}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: TFTP.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 618\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'TFTP': 5000}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: UDPLag.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'UDP-lag': 5000}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: LDAP.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'NetBIOS': 4992, 'BENIGN': 8}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: MSSQL.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'LDAP': 4994, 'BENIGN': 6}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: NetBIOS.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'NetBIOS': 5000}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: Portmap.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'BENIGN': 3707, 'Portmap': 1293}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: Syn.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'Syn': 5000}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: UDP.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'MSSQL': 5000}\n",
      "------------------------------------------------------------\n",
      "âœ… æ–‡ä»¶: UDPLag.csv\n",
      "   â–¶ï¸ è¡Œæ•°: 5000, åˆ—æ•°: 88\n",
      "   ğŸ§± ç¼ºå¤±å€¼æ€»æ•°: 0\n",
      "   ğŸ·ï¸ æ ‡ç­¾åˆ—: Label, åˆ†å¸ƒ: {'UDP': 5000}\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ“Š æ‰€æœ‰æ ‡å‡†åŒ–åˆ—ååŠå‡ºç°é¢‘æ¬¡ï¼ˆå…± 88 ä¸ªï¼‰ï¼š\n",
      "Unnamed: 0: 18\n",
      "Flow ID: 18\n",
      "Source IP: 18\n",
      "Source Port: 18\n",
      "Destination IP: 18\n",
      "Destination Port: 18\n",
      "Protocol: 18\n",
      "Timestamp: 18\n",
      "Flow Duration: 18\n",
      "Total Fwd Packets: 18\n",
      "Total Backward Packets: 18\n",
      "Total Length of Fwd Packets: 18\n",
      "Total Length of Bwd Packets: 18\n",
      "Fwd Packet Length Max: 18\n",
      "Fwd Packet Length Min: 18\n",
      "Fwd Packet Length Mean: 18\n",
      "Fwd Packet Length Std: 18\n",
      "Bwd Packet Length Max: 18\n",
      "Bwd Packet Length Min: 18\n",
      "Bwd Packet Length Mean: 18\n",
      "Bwd Packet Length Std: 18\n",
      "Flow Bytes/s: 18\n",
      "Flow Packets/s: 18\n",
      "Flow IAT Mean: 18\n",
      "Flow IAT Std: 18\n",
      "Flow IAT Max: 18\n",
      "Flow IAT Min: 18\n",
      "Fwd IAT Total: 18\n",
      "Fwd IAT Mean: 18\n",
      "Fwd IAT Std: 18\n",
      "Fwd IAT Max: 18\n",
      "Fwd IAT Min: 18\n",
      "Bwd IAT Total: 18\n",
      "Bwd IAT Mean: 18\n",
      "Bwd IAT Std: 18\n",
      "Bwd IAT Max: 18\n",
      "Bwd IAT Min: 18\n",
      "Fwd PSH Flags: 18\n",
      "Bwd PSH Flags: 18\n",
      "Fwd URG Flags: 18\n",
      "Bwd URG Flags: 18\n",
      "Fwd Header Length: 18\n",
      "Bwd Header Length: 18\n",
      "Fwd Packets/s: 18\n",
      "Bwd Packets/s: 18\n",
      "Min Packet Length: 18\n",
      "Max Packet Length: 18\n",
      "Packet Length Mean: 18\n",
      "Packet Length Std: 18\n",
      "Packet Length Variance: 18\n",
      "FIN Flag Count: 18\n",
      "SYN Flag Count: 18\n",
      "RST Flag Count: 18\n",
      "PSH Flag Count: 18\n",
      "ACK Flag Count: 18\n",
      "URG Flag Count: 18\n",
      "CWE Flag Count: 18\n",
      "ECE Flag Count: 18\n",
      "Down/Up Ratio: 18\n",
      "Average Packet Size: 18\n",
      "Avg Fwd Segment Size: 18\n",
      "Avg Bwd Segment Size: 18\n",
      "Fwd Header Length.1: 18\n",
      "Fwd Avg Bytes/Bulk: 18\n",
      "Fwd Avg Packets/Bulk: 18\n",
      "Fwd Avg Bulk Rate: 18\n",
      "Bwd Avg Bytes/Bulk: 18\n",
      "Bwd Avg Packets/Bulk: 18\n",
      "Bwd Avg Bulk Rate: 18\n",
      "Subflow Fwd Packets: 18\n",
      "Subflow Fwd Bytes: 18\n",
      "Subflow Bwd Packets: 18\n",
      "Subflow Bwd Bytes: 18\n",
      "Init_Win_bytes_forward: 18\n",
      "Init_Win_bytes_backward: 18\n",
      "act_data_pkt_fwd: 18\n",
      "min_seg_size_forward: 18\n",
      "Active Mean: 18\n",
      "Active Std: 18\n",
      "Active Max: 18\n",
      "Active Min: 18\n",
      "Idle Mean: 18\n",
      "Idle Std: 18\n",
      "Idle Max: 18\n",
      "Idle Min: 18\n",
      "SimillarHTTP: 18\n",
      "Inbound: 18\n",
      "Label: 18\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T05:47:21.980563Z",
     "start_time": "2025-05-09T05:47:21.965238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä»£ç å— 1.2\n",
    "\n",
    "import json\n",
    "\n",
    "# æ’é™¤æ‰æ ‡ç­¾åˆ—\n",
    "standard_columns = [col for col in column_counter if col != \"Label\"]\n",
    "\n",
    "# ä¿å­˜ä¸º JSON æ–‡ä»¶\n",
    "with open(\"feature_columns.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(standard_columns, f, indent=2)\n",
    "\n",
    "print(f\"âœ… å·²ä¿å­˜æ ‡å‡†å­—æ®µåˆ— {len(standard_columns)} é¡¹ åˆ° feature_columns.json\")\n"
   ],
   "id": "84557bc4063d4936",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²ä¿å­˜æ ‡å‡†å­—æ®µåˆ— 87 é¡¹ åˆ° feature_columns.json\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T06:29:09.418491Z",
     "start_time": "2025-05-09T06:17:40.936540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä»£ç å— 1.3ï¼ˆæœ€ç»ˆå¢å¼ºç‰ˆï¼šä¼˜å…ˆä¿ç•™BENIGNï¼‰\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "# åŠ è½½æ ‡å‡†å­—æ®µ\n",
    "with open(\"feature_columns.json\", \"r\") as f:\n",
    "    standard_columns = json.load(f)\n",
    "\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "os.makedirs(\"data/processed_npz\", exist_ok=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for path in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(path, low_memory=False)\n",
    "        df.columns = [col.strip() for col in df.columns]\n",
    "\n",
    "        if \"Label\" not in df.columns:\n",
    "            continue\n",
    "\n",
    "        df[\"Label\"] = df[\"Label\"].astype(str)\n",
    "        benign_df = df[df[\"Label\"].str.upper() == \"BENIGN\"]\n",
    "        attack_df = df[df[\"Label\"].str.upper() != \"BENIGN\"]\n",
    "\n",
    "        # é‡‡æ ·ç­–ç•¥ï¼šå…¨ä¿ç•™ BENIGN + éšæœºæ”»å‡»è¡¥è¶³\n",
    "        max_rows = 100000\n",
    "        keep_benign = benign_df.copy()\n",
    "        need_attacks = max_rows - len(keep_benign)\n",
    "        sampled_attack = attack_df.sample(n=need_attacks, random_state=42) if need_attacks > 0 else attack_df.iloc[0:0]\n",
    "\n",
    "        df_sampled = pd.concat([keep_benign, sampled_attack]).sample(frac=1, random_state=42)\n",
    "\n",
    "        # æ ‡ç­¾ç¼–ç \n",
    "        y = df_sampled[\"Label\"].apply(lambda x: 0 if x.upper() == \"BENIGN\" else 1).values\n",
    "\n",
    "        # ç‰¹å¾å¤„ç†\n",
    "        X = df_sampled.reindex(columns=standard_columns)\n",
    "        X = X.apply(pd.to_numeric, errors=\"coerce\")\n",
    "        X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "        # å½’ä¸€åŒ–ï¼ˆç¬¬ä¸€æ¬¡æ‹Ÿåˆï¼‰\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        # ä¿å­˜\n",
    "        base = os.path.splitext(os.path.basename(path))[0]\n",
    "        np.savez_compressed(f\"data/processed_npz/{base}.npz\", X=X_scaled, y=y)\n",
    "        pd.DataFrame(X_scaled, columns=standard_columns).to_csv(f\"data/processed/{base}.csv\", index=False)\n",
    "        print(f\"âœ… æ¸…æ´—+é‡‡æ ·: {base} | BENIGN: {len(keep_benign)}, ATTACK: {len(sampled_attack)}, æ€»: {len(y)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ é”™è¯¯å¤„ç†: {path}, åŸå› : {e}\")\n",
    "\n",
    "# ä¿å­˜å½’ä¸€åŒ–å™¨\n",
    "dump(scaler, \"scaler.pkl\")\n",
    "print(\"âœ… å·²ä¿å­˜å½’ä¸€åŒ–å™¨ scaler.pkl\")\n"
   ],
   "id": "b0f6c273da84448b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¸…æ´—+é‡‡æ ·: DrDoS_DNS | BENIGN: 3402, ATTACK: 96598, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: DrDoS_LDAP | BENIGN: 1612, ATTACK: 98388, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: DrDoS_MSSQL | BENIGN: 2006, ATTACK: 97994, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: DrDoS_NetBIOS | BENIGN: 1707, ATTACK: 98293, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: DrDoS_NTP | BENIGN: 14365, ATTACK: 85635, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: DrDoS_SNMP | BENIGN: 1507, ATTACK: 98493, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: DrDoS_SSDP | BENIGN: 763, ATTACK: 99237, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: DrDoS_UDP | BENIGN: 2157, ATTACK: 97843, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: Syn | BENIGN: 392, ATTACK: 99608, æ€»: 100000\n",
      "âŒ é”™è¯¯å¤„ç†: data/raw/CICDDoS2019\\CSV-01-12\\01-12\\TFTP.csv, åŸå› : Error tokenizing data. C error: out of memory\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: UDPLag | BENIGN: 3705, ATTACK: 96295, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: LDAP | BENIGN: 5124, ATTACK: 94876, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: MSSQL | BENIGN: 2794, ATTACK: 97206, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: NetBIOS | BENIGN: 1321, ATTACK: 98679, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: Portmap | BENIGN: 4734, ATTACK: 95266, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: Syn | BENIGN: 35790, ATTACK: 64210, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: UDP | BENIGN: 3134, ATTACK: 96866, æ€»: 100000\n",
      "âœ… æ¸…æ´—+é‡‡æ ·: UDPLag | BENIGN: 4068, ATTACK: 95932, æ€»: 100000\n",
      "âœ… å·²ä¿å­˜å½’ä¸€åŒ–å™¨ scaler.pkl\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T06:36:51.605938Z",
     "start_time": "2025-05-09T06:36:28.020464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä»£ç å— 1.4ï¼ˆä¿®è®¢ç‰ˆï¼šåŸºäº Timestamp æ’åºæ»‘çª—ï¼‰\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "npz_dir = \"data/processed_npz\"\n",
    "csv_dir = \"data/processed\"\n",
    "out_dir = \"data/processed_npz_seq\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "window_size = 3\n",
    "step = 3\n",
    "\n",
    "npz_files = glob(os.path.join(npz_dir, \"*.npz\"))\n",
    "\n",
    "for npz_path in npz_files:\n",
    "    try:\n",
    "        base = os.path.splitext(os.path.basename(npz_path))[0]\n",
    "        csv_path = os.path.join(csv_dir, f\"{base}.csv\")\n",
    "\n",
    "        # è½½å…¥ CSV ä¿ç•™æ—¶é—´é¡ºåº\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], errors=\"coerce\")\n",
    "        df = df.sort_values(\"Timestamp\").reset_index(drop=True)\n",
    "\n",
    "        # åŒæ—¶è¯»å–æ ‡ç­¾\n",
    "        data = np.load(npz_path)\n",
    "        y = data[\"y\"]\n",
    "\n",
    "        # åŒ¹é… Timestamp æ’åºåçš„ç´¢å¼•ï¼ˆå¯èƒ½ä¸¢å¼ƒæ— æ•ˆæ—¶é—´ï¼‰\n",
    "        valid_idx = df[\"Timestamp\"].notnull()\n",
    "        df = df[valid_idx]\n",
    "        y = y[valid_idx.values]\n",
    "\n",
    "        X = df.drop(columns=[\"Timestamp\"]).values  # å»æ‰æ—¶é—´æˆ³åˆ—\n",
    "\n",
    "        # æ»‘çª—åˆ‡ç‰‡\n",
    "        X_seq, y_seq = [], []\n",
    "        for i in range(0, len(X) - window_size + 1, step):\n",
    "            window_y = y[i:i + window_size]\n",
    "            if np.all(window_y == window_y[0]):\n",
    "                X_seq.append(X[i:i + window_size])\n",
    "                y_seq.append(window_y[0])\n",
    "\n",
    "        np.savez_compressed(f\"{out_dir}/{base}_seq.npz\", X=np.array(X_seq), y=np.array(y_seq))\n",
    "        print(f\"âœ… æ—¶åºåˆ‡ç‰‡: {base}, æœ‰æ•ˆåºåˆ—: {len(y_seq)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åˆ‡ç‰‡å¤±è´¥: {npz_path}, åŸå› : {e}\")\n"
   ],
   "id": "bc92106e96f8bea4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ—¶åºåˆ‡ç‰‡: DrDoS_DNS, æœ‰æ•ˆåºåˆ—: 30035\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: DrDoS_LDAP, æœ‰æ•ˆåºåˆ—: 31752\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: DrDoS_MSSQL, æœ‰æ•ˆåºåˆ—: 31371\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: DrDoS_NetBIOS, æœ‰æ•ˆåºåˆ—: 31658\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: DrDoS_NTP, æœ‰æ•ˆåºåˆ—: 21048\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: DrDoS_SNMP, æœ‰æ•ˆåºåˆ—: 31855\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: DrDoS_SSDP, æœ‰æ•ˆåºåˆ—: 32577\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: DrDoS_UDP, æœ‰æ•ˆåºåˆ—: 31226\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: LDAP, æœ‰æ•ˆåºåˆ—: 28468\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: MSSQL, æœ‰æ•ˆåºåˆ—: 30612\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: NetBIOS, æœ‰æ•ˆåºåˆ—: 32033\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: Portmap, æœ‰æ•ˆåºåˆ—: 28820\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: Syn, æœ‰æ•ˆåºåˆ—: 10371\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: UDP, æœ‰æ•ˆåºåˆ—: 30292\n",
      "âœ… æ—¶åºåˆ‡ç‰‡: UDPLag, æœ‰æ•ˆåºåˆ—: 29425\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T06:37:16.494839Z",
     "start_time": "2025-05-09T06:37:04.998552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä»£ç å— 1.5ï¼ˆä¿®å¤ï¼šè·³è¿‡ç±»åˆ«ä¸è¶³æ–‡ä»¶ï¼‰\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seq_dir = \"data/processed_npz_seq\"\n",
    "out_path = \"data/final_dataset\"\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_all, y_all = [], []\n",
    "\n",
    "for path in glob(os.path.join(seq_dir, \"*_seq.npz\")):\n",
    "    try:\n",
    "        data = np.load(path)\n",
    "        X, y = data[\"X\"], data[\"y\"]\n",
    "        if len(np.unique(y)) < 2:\n",
    "            print(f\"âš ï¸ è·³è¿‡: {os.path.basename(path)}ï¼Œä»…åŒ…å«ä¸€ä¸ªç±»åˆ«\")\n",
    "            continue\n",
    "        X_all.append(X)\n",
    "        y_all.append(y)\n",
    "        print(f\"âœ… è½½å…¥: {os.path.basename(path)}, åºåˆ—æ•°: {len(y)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åŠ è½½å¤±è´¥: {path}, åŸå› : {e}\")\n",
    "\n",
    "X_all = np.concatenate(X_all, axis=0)\n",
    "y_all = np.concatenate(y_all, axis=0)\n",
    "print(f\"ğŸ“¦ åˆå¹¶åæ ·æœ¬æ•°: {len(y_all)}, è¾“å…¥å½¢çŠ¶: {X_all.shape}, æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(y_all)}\")\n",
    "\n",
    "# åˆ’åˆ†æ•°æ®é›†\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_all, y_all, test_size=0.15, random_state=42, stratify=y_all)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp)\n",
    "\n",
    "# ä¿å­˜\n",
    "np.savez_compressed(os.path.join(out_path, \"train.npz\"), X=X_train, y=y_train)\n",
    "np.savez_compressed(os.path.join(out_path, \"val.npz\"), X=X_val, y=y_val)\n",
    "np.savez_compressed(os.path.join(out_path, \"test.npz\"), X=X_test, y=y_test)\n",
    "print(\"âœ… åˆ’åˆ†å¹¶ä¿å­˜å®Œæ¯•ï¼štrain/val/test.npz\")\n"
   ],
   "id": "c640515797c3e827",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è½½å…¥: DrDoS_DNS_seq.npz, åºåˆ—æ•°: 30035\n",
      "âœ… è½½å…¥: DrDoS_LDAP_seq.npz, åºåˆ—æ•°: 31752\n",
      "âœ… è½½å…¥: DrDoS_MSSQL_seq.npz, åºåˆ—æ•°: 31371\n",
      "âœ… è½½å…¥: DrDoS_NetBIOS_seq.npz, åºåˆ—æ•°: 31658\n",
      "âœ… è½½å…¥: DrDoS_NTP_seq.npz, åºåˆ—æ•°: 21048\n",
      "âœ… è½½å…¥: DrDoS_SNMP_seq.npz, åºåˆ—æ•°: 31855\n",
      "âš ï¸ è·³è¿‡: DrDoS_SSDP_seq.npzï¼Œä»…åŒ…å«ä¸€ä¸ªç±»åˆ«\n",
      "âœ… è½½å…¥: DrDoS_UDP_seq.npz, åºåˆ—æ•°: 31226\n",
      "âœ… è½½å…¥: LDAP_seq.npz, åºåˆ—æ•°: 28468\n",
      "âœ… è½½å…¥: MSSQL_seq.npz, åºåˆ—æ•°: 30612\n",
      "âœ… è½½å…¥: NetBIOS_seq.npz, åºåˆ—æ•°: 32033\n",
      "âœ… è½½å…¥: Portmap_seq.npz, åºåˆ—æ•°: 28820\n",
      "âœ… è½½å…¥: Syn_seq.npz, åºåˆ—æ•°: 10371\n",
      "âœ… è½½å…¥: UDPLag_seq.npz, åºåˆ—æ•°: 29425\n",
      "âœ… è½½å…¥: UDP_seq.npz, åºåˆ—æ•°: 30292\n",
      "ğŸ“¦ åˆå¹¶åæ ·æœ¬æ•°: 398966, è¾“å…¥å½¢çŠ¶: (398966, 3, 86), æ ‡ç­¾åˆ†å¸ƒ: [  1693 397273]\n",
      "âœ… åˆ’åˆ†å¹¶ä¿å­˜å®Œæ¯•ï¼štrain/val/test.npz\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:20:41.434527Z",
     "start_time": "2025-05-09T07:20:39.990921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä»£ç å— 2.1\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=86, hidden_dim=64, lstm_layers=1, dropout=0.3):\n",
    "        super(CNNLSTMClassifier, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_dim, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_dim,\n",
    "                            num_layers=lstm_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (B, T, F) â†’ transpose for CNN\n",
    "        x = x.permute(0, 2, 1)  # (B, F, T)\n",
    "        x = self.cnn(x)         # (B, 128, T)\n",
    "        x = x.permute(0, 2, 1)  # (B, T, 128)\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)     # (B, T, 2*hidden)\n",
    "        out = lstm_out[:, -1, :]       # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥\n",
    "        out = self.classifier(out)     # (B, 1)\n",
    "        return out.squeeze(1)          # (B,)\n",
    "\n",
    "# æµ‹è¯•æ¨¡å‹è¾“å‡º\n",
    "model = CNNLSTMClassifier()\n",
    "x_dummy = torch.randn(8, 3, 86)\n",
    "y_pred = model(x_dummy)\n",
    "print(\"âœ… æ¨¡å‹è¾“å‡ºå½¢çŠ¶:\", y_pred.shape)  # åº”è¯¥æ˜¯ [8]\n"
   ],
   "id": "482c3c9a3e014d9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å‹è¾“å‡ºå½¢çŠ¶: torch.Size([8])\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:20:50.394914Z",
     "start_time": "2025-05-09T07:20:43.719947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä»£ç å— 2.2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# é…ç½®\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"âœ… å½“å‰è®¾å¤‡:\", DEVICE)\n",
    "\n",
    "# åŠ è½½æ•°æ®\n",
    "def load_dataset(path):\n",
    "    data = np.load(path)\n",
    "    X = torch.tensor(data[\"X\"], dtype=torch.float32)\n",
    "    y = torch.tensor(data[\"y\"], dtype=torch.float32)\n",
    "    return TensorDataset(X, y)\n",
    "\n",
    "train_set = load_dataset(\"data/final_dataset/train.npz\")\n",
    "val_set = load_dataset(\"data/final_dataset/val.npz\")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°\n",
    "model = CNNLSTMClassifier().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.BCELoss()  # è¾“å‡ºä¸º Sigmoid åæ¦‚ç‡\n",
    "\n",
    "print(f\"âœ… æ•°æ®åŠ è½½å®Œæˆï¼šè®­ç»ƒæ ·æœ¬ {len(train_set)}ï¼ŒéªŒè¯æ ·æœ¬ {len(val_set)}\")\n"
   ],
   "id": "6daf886c8b8a1697",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å½“å‰è®¾å¤‡: cuda\n",
      "âœ… æ•°æ®åŠ è½½å®Œæˆï¼šè®­ç»ƒæ ·æœ¬ 279266ï¼ŒéªŒè¯æ ·æœ¬ 59855\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T07:22:53.162156Z",
     "start_time": "2025-05-09T07:20:54.185172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä»£ç å— 2.3\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "\n",
    "EPOCHS = 10\n",
    "BEST_F1 = 0.0\n",
    "save_path = \"model.pt\"\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    y_true_train, y_pred_train = [], []\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        preds = (outputs >= 0.5).float()\n",
    "        y_true_train.extend(y_batch.cpu().numpy())\n",
    "        y_pred_train.extend(preds.cpu().numpy())\n",
    "\n",
    "    train_acc = accuracy_score(y_true_train, y_pred_train)\n",
    "    train_f1 = f1_score(y_true_train, y_pred_train)\n",
    "    print(f\"ğŸ“˜ Epoch {epoch} | Train Loss: {np.mean(train_losses):.4f} | Acc: {train_acc:.4f} | F1: {train_f1:.4f}\")\n",
    "\n",
    "    # è¯„ä¼°éªŒè¯é›†\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    y_true_val, y_pred_val = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            y_true_val.extend(y_batch.cpu().numpy())\n",
    "            y_pred_val.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_f1 = f1_score(y_true_val, y_pred_val)\n",
    "    val_acc = accuracy_score(y_true_val, y_pred_val)\n",
    "    print(f\"ğŸ§ª Validation | Loss: {np.mean(val_losses):.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
    "\n",
    "    # ä¿å­˜æœ€å¥½æ¨¡å‹\n",
    "    if val_f1 > BEST_F1:\n",
    "        BEST_F1 = val_f1\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"âœ… Saved best model to {save_path}\")\n",
    "\n"
   ],
   "id": "943e6984ff6f4f96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 1 | Train Loss: 0.0177 | Acc: 0.9948 | F1: 0.9974\n",
      "ğŸ§ª Validation | Loss: 0.0136 | Acc: 0.9958 | F1: 0.9979\n",
      "âœ… Saved best model to model.pt\n",
      "ğŸ“˜ Epoch 2 | Train Loss: 0.0139 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ§ª Validation | Loss: 0.0135 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ“˜ Epoch 3 | Train Loss: 0.0138 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ§ª Validation | Loss: 0.0135 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ“˜ Epoch 4 | Train Loss: 0.0138 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ§ª Validation | Loss: 0.0135 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ“˜ Epoch 5 | Train Loss: 0.0137 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ§ª Validation | Loss: 0.0135 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ“˜ Epoch 6 | Train Loss: 0.0136 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ§ª Validation | Loss: 0.0136 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ“˜ Epoch 7 | Train Loss: 0.0137 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ§ª Validation | Loss: 0.0136 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ“˜ Epoch 8 | Train Loss: 0.0137 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ§ª Validation | Loss: 0.0136 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ“˜ Epoch 9 | Train Loss: 0.0136 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ§ª Validation | Loss: 0.0136 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ“˜ Epoch 10 | Train Loss: 0.0137 | Acc: 0.9958 | F1: 0.9979\n",
      "ğŸ§ª Validation | Loss: 0.0136 | Acc: 0.9958 | F1: 0.9979\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T08:05:21.350312Z",
     "start_time": "2025-05-09T08:05:18.814418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä»£ç å— 2.4\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "model = CNNLSTMClassifier().to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "# åŠ è½½æµ‹è¯•é›†\n",
    "test_data = np.load(\"data/final_dataset/test.npz\")\n",
    "X_test = torch.tensor(test_data[\"X\"], dtype=torch.float32).to(DEVICE)\n",
    "y_test = torch.tensor(test_data[\"y\"], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# é¢„æµ‹\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    preds = (outputs >= 0.5).float()\n",
    "\n",
    "# è®¡ç®—å‡†ç¡®ç‡ä¸ F1 å€¼\n",
    "y_true = y_test.cpu().numpy()\n",
    "y_pred = preds.cpu().numpy()\n",
    "\n",
    "test_acc = accuracy_score(y_true, y_pred)\n",
    "test_f1 = f1_score(y_true, y_pred)\n",
    "test_precision = precision_score(y_true, y_pred)\n",
    "test_recall = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f\"ğŸ“Š Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"ğŸ“Š Test F1: {test_f1:.4f}\")\n",
    "print(f\"ğŸ“Š Test Precision: {test_precision:.4f}\")\n",
    "print(f\"ğŸ“Š Test Recall: {test_recall:.4f}\")\n"
   ],
   "id": "708ef08d19ad74be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Test Accuracy: 0.9958\n",
      "ğŸ“Š Test F1: 0.9979\n",
      "ğŸ“Š Test Precision: 0.9958\n",
      "ğŸ“Š Test Recall: 1.0000\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ä»£ç å— 2.5\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "# éšæœºé€‰æ‹©ä¸€ä¸ª npz æ–‡ä»¶\n",
    "npz_files = [f for f in os.listdir(\"data/final_dataset/\") if f.endswith(\".npz\")]\n",
    "random_file = random.choice(npz_files)\n",
    "\n",
    "# åŠ è½½é€‰å®šçš„ npz æ–‡ä»¶\n",
    "print(f\"ğŸ”„ æ­£åœ¨åŠ è½½æ–‡ä»¶: {random_file}\")\n",
    "data = np.load(os.path.join(\"data/final_dataset\", random_file))\n",
    "\n",
    "X_test = torch.tensor(data[\"X\"], dtype=torch.float32).to(DEVICE)\n",
    "y_test = torch.tensor(data[\"y\"], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# é¢„æµ‹\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    preds = (outputs >= 0.5).float()\n",
    "\n",
    "# è®¡ç®—å‡†ç¡®ç‡ä¸ F1 å€¼\n",
    "y_true = y_test.cpu().numpy()\n",
    "y_pred = preds.cpu().numpy()\n",
    "\n",
    "test_acc = accuracy_score(y_true, y_pred)\n",
    "test_f1 = f1_score(y_true, y_pred)\n",
    "test_precision = precision_score(y_true, y_pred)\n",
    "test_recall = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f\"ğŸ“Š Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"ğŸ“Š Test F1: {test_f1:.4f}\")\n",
    "print(f\"ğŸ“Š Test Precision: {test_precision:.4f}\")\n",
    "print(f\"ğŸ“Š Test Recall: {test_recall:.4f}\")\n"
   ],
   "id": "ed629a580f0e0e4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T08:11:44.322992Z",
     "start_time": "2025-05-09T08:11:43.936749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ä»£ç å— 2.6ï¼ˆä¿®æ­£ï¼šä» data/processed_npz_seq åŠ è½½ï¼‰\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# ä»åˆå¹¶å‰çš„æ•°æ®é›†ä¸­éšæœºé€‰æ‹©ä¸€ä¸ª npz æ–‡ä»¶\n",
    "npz_files = [f for f in os.listdir(\"data/processed_npz_seq\") if f.endswith(\".npz\")]\n",
    "random_file = random.choice(npz_files)\n",
    "\n",
    "# åŠ è½½é€‰å®šçš„ npz æ–‡ä»¶\n",
    "print(f\"ğŸ”„ æ­£åœ¨åŠ è½½æ–‡ä»¶: {random_file}\")\n",
    "data = np.load(os.path.join(\"data/processed_npz_seq\", random_file))\n",
    "\n",
    "X_test = torch.tensor(data[\"X\"], dtype=torch.float32).to(DEVICE)\n",
    "y_test = torch.tensor(data[\"y\"], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# é¢„æµ‹\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    preds = (outputs >= 0.5).float()\n",
    "\n",
    "# è®¡ç®—å‡†ç¡®ç‡ä¸ F1 å€¼\n",
    "y_true = y_test.cpu().numpy()\n",
    "y_pred = preds.cpu().numpy()\n",
    "\n",
    "test_acc = accuracy_score(y_true, y_pred)\n",
    "test_f1 = f1_score(y_true, y_pred)\n",
    "test_precision = precision_score(y_true, y_pred)\n",
    "test_recall = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f\"ğŸ“Š Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"ğŸ“Š Test F1: {test_f1:.4f}\")\n",
    "print(f\"ğŸ“Š Test Precision: {test_precision:.4f}\")\n",
    "print(f\"ğŸ“Š Test Recall: {test_recall:.4f}\")\n"
   ],
   "id": "754e49f4acef63b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ æ­£åœ¨åŠ è½½æ–‡ä»¶: UDP_seq.npz\n",
      "ğŸ“Š Test Accuracy: 1.0000\n",
      "ğŸ“Š Test F1: 1.0000\n",
      "ğŸ“Š Test Precision: 1.0000\n",
      "ğŸ“Š Test Recall: 1.0000\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ddos",
   "language": "python",
   "display_name": "Python (DDOS)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
